{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging\n",
    "\n",
    "Since when cleaning there was an issue with two universities: Boston College and Northeastern. Boston College had extra columns that we weren't sure what to do with, Northeastern whereas had different columns from other files so we had to fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_excel('../data/sorted/merged_missing_bc_ne.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge Boston College and Northeaster University\n",
    "bc = pd.read_csv(\"../data/sorted/universities/BostonCollege.csv\")\n",
    "neu = pd.read_csv(\"../data/sorted/universities/NortheasternUniversity.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>level_of_study</th>\n",
       "      <th>full_time</th>\n",
       "      <th>extra_large_unit</th>\n",
       "      <th>expected_graduation_term</th>\n",
       "      <th>housing_type</th>\n",
       "      <th>at_home</th>\n",
       "      <th>year_range</th>\n",
       "      <th>university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>Bay St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Boston off-campus not-at-home (formall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Boston College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775</td>\n",
       "      <td>Beacon St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apt#B1 517</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Boston off-campus not-at-home (formall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Boston College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>Bowdoin St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Boston off-campus not-at-home (formall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Boston College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PO Box 1202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Boston off-campus not-at-home (formall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Boston College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Causeway St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1702</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Boston off-campus not-at-home (formall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Boston College</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  street_number  street_name street_suffix unit_number  zip_code  \\\n",
       "0            34       Bay St           NaN         NaN    2171.0   \n",
       "1           775    Beacon St           NaN  Apt#B1 517    2215.0   \n",
       "2           242   Bowdoin St           NaN         NaN    2122.0   \n",
       "3           NaN  PO Box 1202           NaN         NaN    2134.0   \n",
       "4            50  Causeway St           NaN        1702    2114.0   \n",
       "\n",
       "  level_of_study  full_time extra_large_unit expected_graduation_term  \\\n",
       "0              U  Full Time                N                      NaN   \n",
       "1              U  Full Time                N                      NaN   \n",
       "2              U  Full Time                N                      NaN   \n",
       "3              U  Part Time                N                      NaN   \n",
       "4              U  Part Time                N                      NaN   \n",
       "\n",
       "                                        housing_type at_home year_range  \\\n",
       "0  City of Boston off-campus not-at-home (formall...     NaN  2022-2023   \n",
       "1  City of Boston off-campus not-at-home (formall...     NaN  2022-2023   \n",
       "2  City of Boston off-campus not-at-home (formall...     NaN  2022-2023   \n",
       "3  City of Boston off-campus not-at-home (formall...     NaN  2022-2023   \n",
       "4  City of Boston off-campus not-at-home (formall...     NaN  2022-2023   \n",
       "\n",
       "       university  \n",
       "0  Boston College  \n",
       "1  Boston College  \n",
       "2  Boston College  \n",
       "3  Boston College  \n",
       "4  Boston College  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street_number | street_name | street_suffix | unit_number | zip_code | level_of_study | full_time | extra_large_unit | at_home | year_range | university'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' | '.join(list(merged.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street_number | street_name | street_suffix | unit_number | zip_code | level_of_study | full_time | extra_large_unit | expected_graduation_term | housing_type | at_home | year_range | university'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' | '.join(list(bc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street_number | street_name | street_suffix | unit_number | zip_code | level_of_study | full_time | extra_large_unit | at_home | year_range | university'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' | '.join(list(neu.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the housing_type and expecgted graduation_term columns from bc\n",
    "bc.drop(columns=['housing_type', 'expected_graduation_term'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street_number | street_name | street_suffix | unit_number | zip_code | level_of_study | full_time | extra_large_unit | at_home | year_range | university'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' | '.join(list(bc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can concat the two dataframes\n",
    "bc_neu = pd.concat([bc, neu], ignore_index=True)\n",
    "# now concat to the merged dataframe\n",
    "merged = pd.concat([merged, bc_neu], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../data/sorted/merged_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after everything is merged we can start the cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some of the addresses were not seperated beforehand, but some chunk was seperated, however, upon further inspection, we realized that even seperated, that subset was not perfectly seperated, so we decided to merge all the street related columns into 1 and run the algorithm on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('../data/sorted/merged_full.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['street_number'] = merged['street_number'].fillna('')\n",
    "merged['street_name'] = merged['street_name'].fillna('')\n",
    "merged['street_suffix'] = merged['street_suffix'].fillna('')\n",
    "merged['unit_number'] = merged['unit_number'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['street_name'] = merged['street_number'] + ' ' + merged['street_name'] + ' ' + merged['street_suffix'] + ' ' + merged['unit_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the street_number, street_name, street_suffix, unit_number to empty string\n",
    "merged['street_number'] = ''\n",
    "merged['street_suffix'] = ''\n",
    "merged['unit_number'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from address_parser import parse_address\n",
    "\n",
    "merged[['street_number', 'street_name', 'street_suffix', 'unit_number']] = merged['street_name'].apply(parse_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>level_of_study</th>\n",
       "      <th>full_time</th>\n",
       "      <th>extra_large_unit</th>\n",
       "      <th>at_home</th>\n",
       "      <th>year_range</th>\n",
       "      <th>university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>leighton</td>\n",
       "      <td>rd</td>\n",
       "      <td>None</td>\n",
       "      <td>2136</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Baptist College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>leighton</td>\n",
       "      <td>rd</td>\n",
       "      <td>None</td>\n",
       "      <td>2136</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>Baptist College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>rockwell</td>\n",
       "      <td>st</td>\n",
       "      <td>None</td>\n",
       "      <td>2124</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>Baptist College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>rockwell</td>\n",
       "      <td>st</td>\n",
       "      <td>None</td>\n",
       "      <td>2124</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Baptist College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>milton st</td>\n",
       "      <td>west</td>\n",
       "      <td>None</td>\n",
       "      <td>2136</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At-Home</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>Baptist College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>675</td>\n",
       "      <td>concord</td>\n",
       "      <td>ave</td>\n",
       "      <td>605</td>\n",
       "      <td>2138</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>at-home</td>\n",
       "      <td>2023-2024</td>\n",
       "      <td>Baptist College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>province</td>\n",
       "      <td>street</td>\n",
       "      <td>1106</td>\n",
       "      <td>02108</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48</td>\n",
       "      <td>richfield</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02125</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>langdon</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02119</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>langdon</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02119</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>b street</td>\n",
       "      <td>street</td>\n",
       "      <td>3015</td>\n",
       "      <td>02127</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>643</td>\n",
       "      <td>saratoga</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02128</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>maverick</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02128</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28a</td>\n",
       "      <td>aguadilla</td>\n",
       "      <td>street</td>\n",
       "      <td>a</td>\n",
       "      <td>02118</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>263</td>\n",
       "      <td>talbot</td>\n",
       "      <td>avenue</td>\n",
       "      <td>1</td>\n",
       "      <td>02124</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>lorne</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02124</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>67</td>\n",
       "      <td>cheney</td>\n",
       "      <td>street</td>\n",
       "      <td>1</td>\n",
       "      <td>02121</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>48</td>\n",
       "      <td>brighton</td>\n",
       "      <td>avenue</td>\n",
       "      <td>26</td>\n",
       "      <td>02134</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>ballou</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02124-</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>hendry</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02122</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>660</td>\n",
       "      <td>washington</td>\n",
       "      <td>street</td>\n",
       "      <td>10j</td>\n",
       "      <td>02111</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>mamelon</td>\n",
       "      <td>circle</td>\n",
       "      <td>None</td>\n",
       "      <td>02126</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>683</td>\n",
       "      <td>parker</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02120</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>verrill</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02126</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1120</td>\n",
       "      <td>washington</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02124</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1130</td>\n",
       "      <td>commonwealth</td>\n",
       "      <td>avenue</td>\n",
       "      <td>5</td>\n",
       "      <td>02134</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>150</td>\n",
       "      <td>huntington sh10</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02115</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40</td>\n",
       "      <td>wood</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02126</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>77</td>\n",
       "      <td>exeter</td>\n",
       "      <td>street</td>\n",
       "      <td>2503</td>\n",
       "      <td>02116</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>62</td>\n",
       "      <td>l street</td>\n",
       "      <td>street</td>\n",
       "      <td>2</td>\n",
       "      <td>02127</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>york</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02121</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>19</td>\n",
       "      <td>dacia</td>\n",
       "      <td>street</td>\n",
       "      <td>r</td>\n",
       "      <td>02125</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>67</td>\n",
       "      <td>clarkson</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02125</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>968</td>\n",
       "      <td>river</td>\n",
       "      <td>street</td>\n",
       "      <td>2</td>\n",
       "      <td>02136</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>74</td>\n",
       "      <td>geneva</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02121</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>271</td>\n",
       "      <td>sumner</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02128</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>45</td>\n",
       "      <td>brookledge</td>\n",
       "      <td>street</td>\n",
       "      <td>3</td>\n",
       "      <td>02121</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>151</td>\n",
       "      <td>calumet</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02120</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>71</td>\n",
       "      <td>clement</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02132</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>944</td>\n",
       "      <td>parker</td>\n",
       "      <td>street</td>\n",
       "      <td>382</td>\n",
       "      <td>02130</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>96</td>\n",
       "      <td>brooke</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02125</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>wainwright</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02124</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>victory</td>\n",
       "      <td>road</td>\n",
       "      <td>19</td>\n",
       "      <td>02122</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>128</td>\n",
       "      <td>old ironsides</td>\n",
       "      <td>way</td>\n",
       "      <td>None</td>\n",
       "      <td>02129</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>101</td>\n",
       "      <td>canal</td>\n",
       "      <td>street</td>\n",
       "      <td>518</td>\n",
       "      <td>02114</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>797</td>\n",
       "      <td>huntington</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02115</td>\n",
       "      <td>U</td>\n",
       "      <td>PT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>797</td>\n",
       "      <td>huntington</td>\n",
       "      <td>avenue</td>\n",
       "      <td>None</td>\n",
       "      <td>02115</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>114</td>\n",
       "      <td>winthrop</td>\n",
       "      <td>street</td>\n",
       "      <td>None</td>\n",
       "      <td>02119</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>166</td>\n",
       "      <td>salem</td>\n",
       "      <td>street</td>\n",
       "      <td>1f</td>\n",
       "      <td>02113</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>605</td>\n",
       "      <td>truman</td>\n",
       "      <td>parkway</td>\n",
       "      <td>None</td>\n",
       "      <td>02136</td>\n",
       "      <td>U</td>\n",
       "      <td>FT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Bay State College</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   street_number      street_name street_suffix unit_number    zip_code  \\\n",
       "0             66         leighton            rd        None        2136   \n",
       "1             66         leighton            rd        None        2136   \n",
       "2             50         rockwell            st        None        2124   \n",
       "3             50         rockwell            st        None        2124   \n",
       "4             75        milton st          west        None        2136   \n",
       "5            675          concord           ave         605        2138   \n",
       "6             45         province        street        1106  02108        \n",
       "7             48        richfield        street        None  02125        \n",
       "8             40          langdon        street        None  02119        \n",
       "9             42          langdon        street        None  02119        \n",
       "10            59         b street        street        3015  02127        \n",
       "11           643         saratoga        street        None  02128        \n",
       "12            26         maverick        street        None  02128        \n",
       "13           28a        aguadilla        street           a  02118        \n",
       "14           263           talbot        avenue           1  02124        \n",
       "15            29            lorne        street        None  02124        \n",
       "16            67           cheney        street           1  02121        \n",
       "17            48         brighton        avenue          26  02134        \n",
       "18            77           ballou        avenue        None  02124-       \n",
       "19            34           hendry        street        None  02122        \n",
       "20           660       washington        street         10j  02111        \n",
       "21            20          mamelon        circle        None  02126        \n",
       "22           683           parker        street        None  02120        \n",
       "23            12          verrill        street        None  02126        \n",
       "24          1120       washington        street        None  02124        \n",
       "25          1130     commonwealth        avenue           5  02134        \n",
       "26           150  huntington sh10        avenue        None  02115        \n",
       "27            40             wood        avenue        None  02126        \n",
       "28            77           exeter        street        2503  02116        \n",
       "29            62         l street        street           2  02127        \n",
       "30            12             york        street        None  02121        \n",
       "31            19            dacia        street           r  02125        \n",
       "32            67         clarkson        street        None  02125        \n",
       "33           968            river        street           2  02136        \n",
       "34            74           geneva        avenue        None  02121        \n",
       "35           271           sumner        street        None  02128        \n",
       "36            45       brookledge        street           3  02121        \n",
       "37           151          calumet        street        None  02120        \n",
       "38            71          clement        avenue        None  02132        \n",
       "39           944           parker        street         382  02130        \n",
       "40            96           brooke        avenue        None  02125        \n",
       "41             8       wainwright        street        None  02124        \n",
       "42             9          victory          road          19  02122        \n",
       "43           128    old ironsides           way        None  02129        \n",
       "44           101            canal        street         518  02114        \n",
       "45           797       huntington        avenue        None  02115        \n",
       "46           797       huntington        avenue        None  02115        \n",
       "47           114         winthrop        street        None  02119        \n",
       "48           166            salem        street          1f  02113        \n",
       "49           605           truman       parkway        None  02136        \n",
       "\n",
       "   level_of_study full_time extra_large_unit  at_home year_range  \\\n",
       "0               U        FT                N      NaN  2018-2019   \n",
       "1              U         FT                N      NaN  2018-2019   \n",
       "2               U        PT                N      NaN  2019-2020   \n",
       "3               U        PT                N      NaN  2020-2021   \n",
       "4               U        FT              NaN  At-Home  2023-2024   \n",
       "5               U        PT              NaN  at-home  2023-2024   \n",
       "6               U        FT                N      NaN  2016-2017   \n",
       "7               U        FT                N      NaN  2016-2017   \n",
       "8               U        FT                N      NaN  2016-2017   \n",
       "9               U        FT                N      NaN  2016-2017   \n",
       "10              U        FT                N      NaN  2016-2017   \n",
       "11              U        FT                N      NaN  2016-2017   \n",
       "12              U        PT                N      NaN  2016-2017   \n",
       "13              U        FT                N      NaN  2016-2017   \n",
       "14              U        FT                N      NaN  2016-2017   \n",
       "15              U        FT                N      NaN  2016-2017   \n",
       "16              U        FT                N      NaN  2016-2017   \n",
       "17              U        FT                N      NaN  2016-2017   \n",
       "18              U        FT                N      NaN  2016-2017   \n",
       "19              U        FT                N      NaN  2016-2017   \n",
       "20              U        FT                N      NaN  2016-2017   \n",
       "21              U        FT                N      NaN  2016-2017   \n",
       "22              U        FT                N      NaN  2016-2017   \n",
       "23              U        FT                N      NaN  2016-2017   \n",
       "24              U        FT                N      NaN  2016-2017   \n",
       "25              U        FT                N      NaN  2016-2017   \n",
       "26              U        FT                N      NaN  2016-2017   \n",
       "27              U        FT                N      NaN  2016-2017   \n",
       "28              U        FT                N      NaN  2016-2017   \n",
       "29              U        FT                N      NaN  2016-2017   \n",
       "30              U        FT                N      NaN  2016-2017   \n",
       "31              U        FT                N      NaN  2016-2017   \n",
       "32              U        FT                N      NaN  2016-2017   \n",
       "33              U        FT                N      NaN  2016-2017   \n",
       "34              U        FT                N      NaN  2016-2017   \n",
       "35              U        FT                N      NaN  2016-2017   \n",
       "36              U        PT                N      NaN  2016-2017   \n",
       "37              U        FT                N      NaN  2016-2017   \n",
       "38              U        FT                N      NaN  2016-2017   \n",
       "39              U        FT                N      NaN  2016-2017   \n",
       "40              U        FT                N      NaN  2016-2017   \n",
       "41              U        FT                N      NaN  2016-2017   \n",
       "42              U        PT                N      NaN  2016-2017   \n",
       "43              U        FT                N      NaN  2016-2017   \n",
       "44              U        FT                N      NaN  2016-2017   \n",
       "45              U        PT                N      NaN  2016-2017   \n",
       "46              U        FT                N      NaN  2016-2017   \n",
       "47              U        FT                N      NaN  2016-2017   \n",
       "48              U        FT                N      NaN  2016-2017   \n",
       "49              U        FT                N      NaN  2016-2017   \n",
       "\n",
       "           university  \n",
       "0     Baptist College  \n",
       "1     Baptist College  \n",
       "2     Baptist College  \n",
       "3     Baptist College  \n",
       "4     Baptist College  \n",
       "5     Baptist College  \n",
       "6   Bay State College  \n",
       "7   Bay State College  \n",
       "8   Bay State College  \n",
       "9   Bay State College  \n",
       "10  Bay State College  \n",
       "11  Bay State College  \n",
       "12  Bay State College  \n",
       "13  Bay State College  \n",
       "14  Bay State College  \n",
       "15  Bay State College  \n",
       "16  Bay State College  \n",
       "17  Bay State College  \n",
       "18  Bay State College  \n",
       "19  Bay State College  \n",
       "20  Bay State College  \n",
       "21  Bay State College  \n",
       "22  Bay State College  \n",
       "23  Bay State College  \n",
       "24  Bay State College  \n",
       "25  Bay State College  \n",
       "26  Bay State College  \n",
       "27  Bay State College  \n",
       "28  Bay State College  \n",
       "29  Bay State College  \n",
       "30  Bay State College  \n",
       "31  Bay State College  \n",
       "32  Bay State College  \n",
       "33  Bay State College  \n",
       "34  Bay State College  \n",
       "35  Bay State College  \n",
       "36  Bay State College  \n",
       "37  Bay State College  \n",
       "38  Bay State College  \n",
       "39  Bay State College  \n",
       "40  Bay State College  \n",
       "41  Bay State College  \n",
       "42  Bay State College  \n",
       "43  Bay State College  \n",
       "44  Bay State College  \n",
       "45  Bay State College  \n",
       "46  Bay State College  \n",
       "47  Bay State College  \n",
       "48  Bay State College  \n",
       "49  Bay State College  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning zip-codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_zip = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zip(zip):\n",
    "    # edge case for zip codes that are 8 digits long\n",
    "    #\n",
    "    # if the actual zip is, say, 02134-5678\n",
    "    # but it could've been filled as 21345678\n",
    "    # so we need to add a 0 in front of the zip\n",
    "    # and then add a hyphen in the middle\n",
    "    if len(zip) == 8:\n",
    "        return '0' + zip[:5] + '-' + zip[5:]\n",
    "    \n",
    "    # some zip codes were filled like 2134 instead of 02134\n",
    "    if len(zip) < 5 and zip.isdigit():\n",
    "        return '0' * (5 - len(zip)) + zip\n",
    "\n",
    "    # some zip codes had extra numbers at the end, but not enough to be a full 9-digit zip code    \n",
    "    if len(zip) >= 5 and len(zip) <= 9 and zip[0] == '0':\n",
    "        return zip[:5]\n",
    "    \n",
    "    is_num = is_a_number(zip) # validate if the zip code is a number (if the zip is a subtype of a 5-digit zip code it will be true)\n",
    "\n",
    "    if is_num and len(str(is_num)) <= 5: # example: 2134\n",
    "        zip = str(zip)\n",
    "        return '0' * (5 - len(zip)) + zip\n",
    "\n",
    "    if is_num and is_float(zip): # examples from dataset: 2134.0\n",
    "        zip = int(is_num)\n",
    "        zip = str(zip)\n",
    "        return '0' * (5 - len(zip)) + zip        \n",
    "    \n",
    "        \n",
    "    if '-' in zip: # if the zip code has a hyphen ( 9-digit zip code )\n",
    "        zip = zip.split('-')\n",
    "        \n",
    "        if len(zip[0]) != 5: # if the first part of the zip code is not 5 digits long, then add trailing 0s\n",
    "            zip[0] = '0' * (5 - len(zip[0])) + zip[0]\n",
    "        \n",
    "        if len(zip[1]) != 4: # if the second part of the zip code is not 4 digits long, then the zip code should be the first part only ( 5-digit zip code )\n",
    "            return zip[0]\n",
    "        \n",
    "        # otherwise, return the full 9-digit zip code\n",
    "        return zip[0] + '-' + zip[1]\n",
    "    \n",
    "    # just in case the zip code is a 9-digit zip code without a hyphen\n",
    "    return zip\n",
    "\n",
    "def is_int(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def is_a_number(s):\n",
    "    return is_int(s) or is_float(s)\n",
    "\n",
    "# convert zip_code column to str\n",
    "merged_zip['zip_code'] = merged_zip['zip_code'].astype(str)\n",
    "# strip the zip_code column\n",
    "merged_zip['zip_code'] = merged_zip['zip_code'].str.strip()\n",
    "\n",
    "# get rid of some values, since they are not valid zip codes ( at all )\n",
    "merged_zip.loc[merged_zip['zip_code'] == 'P'] = ''\n",
    "merged_zip.loc[merged_zip['zip_code'] == 'F'] = ''\n",
    "\n",
    "# drop the columns where zip_code == 727420, the reason for this is because that zip code belongs to a different country\n",
    "merged_zip = merged_zip[merged_zip['zip_code'] != '727420']\n",
    "\n",
    "# now apply\n",
    "merged_zip['zip_code'] = merged_zip['zip_code'].apply(fix_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now print zip values that are not 5 digits long and not 10 digits long\n",
    "for zip in merged_zip['zip_code']:\n",
    "    if len(zip) != 5 and len(zip) != 10 and len(zip) != 0:\n",
    "        print(zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level of study cleaning and Full Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a problem with a dataset\n",
    "\n",
    "There were some values that didn't make any sense, and we weren't sure what to do. \n",
    "\n",
    "For example, level_of_study had values such as \"3 UG; 5G\", which according to definition given in the files, made 0 sense.\n",
    "\n",
    "However, then we realized that the data was filled incorrectly. Rather than creating a row for each student, they created one row per address.\n",
    "\n",
    "Therefore, \"3 UG; 5 G\" meant that on that address 3 undergrads reside and 5 graduates. The reason for such a bold assumtion is that the same row value for full time was \"all FT\".\n",
    "\n",
    "Therefore, we decided to approach these two columns at once, since some odd values might have explanation from the full_time column, which they actually did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_los_ft = merged_zip.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = lambda x,y : x in y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few comments beforehand\n",
    "\n",
    "we want to minimze the varience in the values, so we decided that a domain of 3 values for some categorical columns is a good idea. \n",
    "\n",
    "One of the values in the domain is dk - don't know, which helps to avoid any issues that are faced when dealing with nan values\n",
    "\n",
    "Additionally, some values for not proper for the column, such as exchange column for level of study, so we marked such columns as dk\n",
    "\n",
    "Everything else can be seen in the commens before each operation\n",
    "\n",
    "The comments before the actions tell which invalid column names we had worked with.\n",
    "\n",
    "The below cell creates every possible unique combination of level_of_study and full_time\n",
    "\n",
    "As recorded right before, there were 80 unique combination, we dropped that number to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the level_of_study and full_time columns\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].str.strip()\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].str.strip()\n",
    "\n",
    "# lower\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].str.lower()\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].str.lower()\n",
    "\n",
    "# fill na with dk - don't know\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].fillna('dk')\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].fillna('dk')\n",
    "# fill empty string with dk\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].replace('', 'dk')\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].replace('', 'dk')\n",
    "\n",
    "# change exchange student, woods college, woods college of advancing studies to dk\n",
    "merged_los_ft.loc[merged_los_ft['level_of_study'].str.contains('exchange student'), 'level_of_study'] = 'dk'\n",
    "merged_los_ft.loc[merged_los_ft['level_of_study'].str.contains('woods college'), 'level_of_study'] = 'dk'\n",
    "\n",
    "# change d,e,s to dk in full_time\n",
    "f = ['d', 'e', 's']\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].apply(lambda x: 'dk' if filter(x, f) else x)\n",
    "\n",
    "# change half, ht, p, part, half time, part-time, part time to pt\n",
    "f = ['half', 'ht', 'p', 'part', 'half time', 'part-time', 'part time']\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].apply(lambda x: 'pt' if filter(x, f) else x)\n",
    "\n",
    "# change f, fn, full, full time, full-time f1 foreign students, fp to ft\n",
    "f = ['f', 'fn', 'full', 'full time', 'full-time', 'full-time f-1 foreign students', 'fp']\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].apply(lambda x: 'ft' if filter(x, f) else x)\n",
    "\n",
    "# change gr, grad, graduate, 1 g to g\n",
    "f = ['gr', 'grad', 'graduate', '1 g']\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].apply(lambda x: 'g' if filter(x, f) else x)\n",
    "\n",
    "# change ug, undergraduate, undergrad to u\n",
    "f = ['ug', 'undergraduate', 'undergrad']\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].apply(lambda x: 'u' if filter(x, f) else x)\n",
    "\n",
    "# change d, e, s to dk in full_time\n",
    "f = ['d', 'e', 's']\n",
    "merged_los_ft['full_time'] = merged_los_ft['full_time'].apply(lambda x: 'dk' if filter(x, f) else x)\n",
    "\n",
    "# change u and g, g and ug, g and u, u and graduate to both\n",
    "f = ['u and g', 'g and ug', 'g and u', 'u and graduate']\n",
    "merged_los_ft['level_of_study'] = merged_los_ft['level_of_study'].apply(lambda x: 'both' if filter(x, f) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for using both is that we knew that those rows actually contained multiple data points within, so we decided to stick to value of both before we fix that issue\n",
    "\n",
    "Additionally, the explanation for combinations is right below this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations:\n",
    "\n",
    "# '3 ug; 5 g' , 'all ft' = actually 8 rows, 5 g and 3 u, all ft, so we will create new rows for each, and then delete this row\n",
    "# 'both', 'ft' is actually 2 rows, where 1 is g and the other is u, full_time will be ft for both\n",
    "# 'both', 'ft and pt' is actually 2 rows, where 1 is g and the other is u, full_time will be ft for one and pt for the other\n",
    "# 'both', 'pt and ft' is actually 2 rows, where 1 is g and the other is u, full_time will be pt for one and ft for the other\n",
    "# 'g', 'ft and pt' is actually 2 rows, where both are g, full_time will be ft for one and pt for the other\n",
    "\n",
    "# create new rows for '3 ug; 5 g' , 'all ft'\n",
    "# first find the index of the row\n",
    "index = merged_los_ft[(merged_los_ft['level_of_study'] == '3 ug; 5 g') & (merged_los_ft['full_time'] == 'all ft')].index\n",
    "# might be more than 1\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for i in index:\n",
    "    for i in range(3):\n",
    "        t = merged_los_ft.loc[i].copy()\n",
    "        t['level_of_study'] = 'u'\n",
    "        t['full_time'] = 'ft'\n",
    "        new_rows.append(t)\n",
    "\n",
    "    for i in range(5):\n",
    "        t = merged_los_ft.loc[i].copy()\n",
    "        t['level_of_study'] = 'g'\n",
    "        t['full_time'] = 'ft'\n",
    "        new_rows.append(t)\n",
    "\n",
    "# delete the old rows\n",
    "merged_los_ft.drop(index, inplace=True)\n",
    "\n",
    "# add the new rows\n",
    "merged_los_ft = pd.concat([merged_los_ft, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now 'both' and 'ft'\n",
    "index = merged_los_ft[(merged_los_ft['level_of_study'] == 'both') & (merged_los_ft['full_time'] == 'ft')].index\n",
    "# might be more than 1\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for i in index:\n",
    "    t = merged_los_ft.loc[i].copy()\n",
    "    t['level_of_study'] = 'g'\n",
    "    new_rows.append(t)\n",
    "\n",
    "    t = merged_los_ft.loc[i].copy()\n",
    "    t['level_of_study'] = 'u'\n",
    "    new_rows.append(t)\n",
    "\n",
    "# delete the old rows\n",
    "merged_los_ft.drop(index, inplace=True)\n",
    "\n",
    "# add the new rows\n",
    "merged_los_ft = pd.concat([merged_los_ft, pd.DataFrame(new_rows)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now 'both' and 'ft and pt' or 'both' and 'pt and ft'\n",
    "index = merged_los_ft[(merged_los_ft['level_of_study'] == 'both') & ((merged_los_ft['full_time'] == 'ft and pt') | (merged_los_ft['full_time'] == 'pt and ft'))].index\n",
    "# might be more than 1\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for i in index:\n",
    "    t = merged_los_ft.loc[i].copy()\n",
    "    t['level_of_study'] = 'g'\n",
    "    t['full_time'] = 'ft'\n",
    "    new_rows.append(t)\n",
    "\n",
    "    t = merged_los_ft.loc[i].copy()\n",
    "    t['level_of_study'] = 'u'\n",
    "    t['full_time'] = 'pt'\n",
    "    new_rows.append(t)\n",
    "\n",
    "# delete the old rows\n",
    "merged_los_ft.drop(index, inplace=True)\n",
    "\n",
    "# add the new rows\n",
    "merged_los_ft = pd.concat([merged_los_ft, pd.DataFrame(new_rows)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now 'g' and 'ft and pt'\n",
    "index = merged_los_ft[(merged_los_ft['level_of_study'] == 'g') & (merged_los_ft['full_time'] == 'ft and pt')].index\n",
    "# might be more than 1\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for i in index:\n",
    "    t = merged_los_ft.loc[i].copy()\n",
    "    t['full_time'] = 'ft'\n",
    "    new_rows.append(t)\n",
    "\n",
    "    t = merged_los_ft.loc[i].copy()\n",
    "    t['full_time'] = 'pt'\n",
    "    new_rows.append(t)\n",
    "\n",
    "# delete the old rows\n",
    "merged_los_ft.drop(index, inplace=True)\n",
    "\n",
    "# add the new rows\n",
    "merged_los_ft = pd.concat([merged_los_ft, pd.DataFrame(new_rows)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " [['dk', 'dk', 587],\n",
       "  ['dk', 'ft', 126],\n",
       "  ['dk', 'pt', 122],\n",
       "  ['g', 'dk', 182],\n",
       "  ['g', 'ft', 128610],\n",
       "  ['g', 'pt', 12641],\n",
       "  ['u', 'ft', 137100],\n",
       "  ['u', 'pt', 12525]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now count all the unique combinations of level of study and full time and, then just return them as list\n",
    "t = merged_los_ft.groupby(['level_of_study', 'full_time']).size().reset_index().values.tolist()\n",
    "len(t),t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At Home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to map at_home column in the same domain of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_at_home = merged_los_ft.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with empty string in at_home\n",
    "merged_at_home['at_home'] = merged_at_home['at_home'].fillna('')\n",
    "# strip\n",
    "merged_at_home['at_home'] = merged_at_home['at_home'].str.strip()\n",
    "# lower\n",
    "merged_at_home['at_home'] = merged_at_home['at_home'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'at-home',\n",
       " 'not at home',\n",
       " 'home',\n",
       " 'at home',\n",
       " 'not-at-home',\n",
       " 'fransiscan seminary',\n",
       " 'not-at-hhome',\n",
       " 'n',\n",
       " 'y',\n",
       " 'oblate seminary',\n",
       " 'carmelite seminary']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_at_home['at_home'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_home_f = ['at-home','at home','home','y']\n",
    "merged_at_home['at_home'] = merged_at_home['at_home'].apply(lambda x: 'y' if filter(x, at_home_f) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_at_home_f = ['not-at-home','not-at-hhome','n','not at home']\n",
    "merged_at_home['at_home'] = merged_at_home['at_home'].apply(lambda x: 'n' if filter(x, not_at_home_f) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'y', 'n', 'fransiscan seminary', 'oblate seminary', 'carmelite seminary']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_at_home['at_home'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns with oblate seminary\n",
    "merged_at_home.loc[merged_at_home[merged_at_home['at_home'].str.contains('seminary')].index, 'at_home'] = 'dk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with dk\n",
    "merged_at_home['at_home'] = merged_at_home['at_home'].replace('', 'dk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dk', 'y', 'n']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_at_home['at_home'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra large Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_elu = merged_at_home.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N',\n",
       " nan,\n",
       " 'Y',\n",
       " 'y',\n",
       " 'YES',\n",
       " 'n',\n",
       " 'N ',\n",
       " 'No',\n",
       " '',\n",
       " 'do not know',\n",
       " '* ',\n",
       " '*',\n",
       " 'NO']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_elu['extra_large_unit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip\n",
    "merged_elu['extra_large_unit'] = merged_elu['extra_large_unit'].str.strip()\n",
    "# lower\n",
    "merged_elu['extra_large_unit'] = merged_elu['extra_large_unit'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', nan, 'y', 'yes', 'no', '', 'do not know', '*']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_elu['extra_large_unit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_elu.loc[merged_elu['extra_large_unit'] == 'no', 'extra_large_unit'] = 'n'\n",
    "merged_elu.loc[merged_elu['extra_large_unit'] == 'yes', 'extra_large_unit'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', nan, 'y', '', 'do not know', '*']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_elu['extra_large_unit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group do not know, nan and * into dk\n",
    "dk_f = ['do not know', np.nan , '*']\n",
    "merged_elu['extra_large_unit'] = merged_elu['extra_large_unit'].apply(lambda x: 'dk' if filter(x, dk_f) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'dk', 'y', '']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged_elu['extra_large_unit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting rid of nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are done with mapping everything into a more appropriate domain of values, we can now fill na values.\n",
    "\n",
    "Since we filled most other columns with 'dk', we are not left with street columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_elu.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 291893 entries, 0 to 291892\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   street_number     291077 non-null  object\n",
      " 1   street_name       291265 non-null  object\n",
      " 2   street_suffix     283219 non-null  object\n",
      " 3   unit_number       208790 non-null  object\n",
      " 4   zip_code          291893 non-null  object\n",
      " 5   level_of_study    291893 non-null  object\n",
      " 6   full_time         291893 non-null  object\n",
      " 7   extra_large_unit  291893 non-null  object\n",
      " 8   at_home           291893 non-null  object\n",
      " 9   year_range        291893 non-null  object\n",
      " 10  university        291893 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 24.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "street_number         816\n",
       "street_name           628\n",
       "street_suffix        8674\n",
       "unit_number         83103\n",
       "zip_code                0\n",
       "level_of_study          0\n",
       "full_time               0\n",
       "extra_large_unit        0\n",
       "at_home                 0\n",
       "year_range              0\n",
       "university              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na in street_number, street_name, street_suffix, unit_number with empty string\n",
    "df['street_number'] = df['street_number'].fillna('')\n",
    "df['street_name'] = df['street_name'].fillna('')\n",
    "df['street_suffix'] = df['street_suffix'].fillna('')\n",
    "df['unit_number'] = df['unit_number'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to fill street columns with 'dk' since it is not categorical, therefore, shouldn't be filled like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "street_number       0\n",
       "street_name         0\n",
       "street_suffix       0\n",
       "unit_number         0\n",
       "zip_code            0\n",
       "level_of_study      0\n",
       "full_time           0\n",
       "extra_large_unit    0\n",
       "at_home             0\n",
       "year_range          0\n",
       "university          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level_of_study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u - undergraduate\n",
    "\n",
    "g - graduate\n",
    "\n",
    "dk - don't know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## at_home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dk - don't know\n",
    "\n",
    "y - yes\n",
    "\n",
    "n - no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baptist College\n",
    "\n",
    "Bay State College\n",
    "\n",
    "Berklee College of Music\n",
    "\n",
    "Boston Architectural College\n",
    "\n",
    "Boston Conservatory Berklee\n",
    "\n",
    "Boston College\n",
    "\n",
    "Boston University\n",
    "\n",
    "Emerson College\n",
    "\n",
    "Emmanuel College\n",
    "\n",
    "Fisher College\n",
    "\n",
    "Franklin Institute of Technology\n",
    "\n",
    "Harvard University\n",
    "\n",
    "Massachusetts College of Pharmacy and Health Sciences\n",
    "\n",
    "Massachusetts Institute of Technology\n",
    "\n",
    "MGH Institute of Health Professions\n",
    "\n",
    "New England College of Optometry\n",
    "\n",
    "New England Conservatory\n",
    "\n",
    "New England Law\n",
    "\n",
    "Northeastern University\n",
    "\n",
    "Sattler College\n",
    "\n",
    "SHOWA Boston Institute\n",
    "\n",
    "Simmons College\n",
    "\n",
    "St John Seminary\n",
    "\n",
    "Suffolk University\n",
    "\n",
    "Tufts University\n",
    "\n",
    "University of Massachusetts Boston\n",
    "\n",
    "Urban College of Boston\n",
    "\n",
    "Wentworth Institute of Technology\n",
    "\n",
    "Wheelock College\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## year_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-2019\n",
    "\n",
    "2019-2020\n",
    "\n",
    "2020-2021\n",
    "\n",
    "2023-2024\n",
    "\n",
    "2016-2017\n",
    "\n",
    "2017-2018\n",
    "\n",
    "2021-2022\n",
    "\n",
    "2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extra_large_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n - no\n",
    "\n",
    "dk - don't know\n",
    "\n",
    "y - yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('../data/sorted/final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
