{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a universal column format for better experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['street_number','street_name','street_suffix','unit_number','zip_code','level_of_study','full_time','extra_large_unit','at_home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "dir = 'data/universities/NortheasternUniversity/'\n",
    "files = ['2016-2017.xlsx','2017-2018.xlsx','2018-2019.xlsx','2019-2020.xlsx','2020-2021.xlsx','2021-2022.xlsx','2022-2023.xlsx','2023-2024.xlsx']\n",
    "\n",
    "for file in files:\n",
    "    dfs[file] = pd.read_excel(dir + file, sheet_name='Student Addresses')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what are the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Address', 'Neighborhood', 'Zipcode', 'Level', 'Time Status', 'Year', 'Professional School', 'Home or Private?']\n",
      "['6a. \\nStreet #', '6b. \\nStreet Name', '6c. \\nStreet Suffix  ', '6d.\\n Unit #', '6e. \\nZip', '7. \\nUndergraduate (U) or Graduate (G)', '8. \\nFull-time (FT) or \\nPart-time (PT)', '9. \\n 5 or More Undergrads/Unit\\n(Y/N)']\n",
      "['6a. \\nStreet #', '6b. \\nStreet Name', '6c. \\nStreet Suffix  ', '6d.\\n Unit #', '6e. \\nZip', '7. \\nUndergraduate (U) or Graduate (G)', '8. \\nFull-time (FT) or \\nPart-time (PT)', '9. \\n 5 or More Undergrads/Unit\\n(Y/N)']\n",
      "['6a. \\nStreet #', '6b. \\nStreet Name', '6c. \\nStreet Suffix  ', '6d.\\n Unit #', '6e. \\nZip', '7. \\nUndergraduate (U) or Graduate (G)', '8. \\nFull-time (FT) or \\nPart-time (PT)', '9. \\n 5 or More Undergrads/Unit\\n(Y/N)']\n",
      "['Address', 'Neighborhood', 'Zipcode', 'Level', 'Time Status', 'Year', 'Professional School', 'Home or Private?']\n",
      "['Address', 'Neighborhood', 'Zipcode', 'Level', 'Time Status', 'Year', 'Professional School', 'Home or Private?']\n",
      "['Address', 'Neighborhood', 'Zipcode', 'Level', 'Time Status', 'Year', 'Professional School', 'Home or Private?']\n",
      "['Address', 'Neighborhood', 'Zipcode', 'Level', 'Time Status', 'Year', 'Professional School', 'Home or Private?']\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(list(dfs[df].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 distinct groups of columns, let's just group them and print the groups so we know what files to focus on and how to fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address Neighborhood Zipcode Level Time Status Year Professional School Home or Private?\n",
      "['2016-2017.xlsx', '2020-2021.xlsx', '2021-2022.xlsx', '2022-2023.xlsx', '2023-2024.xlsx']\n",
      "6a. Street # 6b. Street Name 6c. Street Suffix   6d. Unit # 6e. Zip 7. Undergraduate (U) or Graduate (G) 8. Full-time (FT) or Part-time (PT) 9.  5 or More Undergrads/Unit(Y/N)\n",
      "['2017-2018.xlsx', '2018-2019.xlsx', '2019-2020.xlsx']\n"
     ]
    }
   ],
   "source": [
    "column_grouping = {}\n",
    "\n",
    "for df in dfs:\n",
    "    c_str = ' '.join(dfs[df].columns)\n",
    "    # remove \\n from string\n",
    "    c_str = re.sub(r'\\n', '', c_str)\n",
    "    \n",
    "    if c_str not in column_grouping:\n",
    "        column_grouping[c_str] = []\n",
    "\n",
    "    column_grouping[c_str].append(df)\n",
    "\n",
    "for c in column_grouping:\n",
    "    print(c)\n",
    "    print(column_grouping[c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the next cell, looking over the dataframes, some of the columns could simply be renamed and it would suffice.\n",
    "\n",
    "The only issue was that the address column has all the addresses, and we have to seperate them into \"street_num\" \"street_name\" \"street_suffix\" \"unit_number\"\n",
    "\n",
    "However, first let's fix the different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the columns that are not in the mapping\n",
    "mapping = {\n",
    "    \"Address\" : \"street_name\",\n",
    "    \"Zipcode\" : \"zip_code\",\n",
    "    \"Level\" : \"level_of_study\",\n",
    "    \"Time Status\" : \"full_time\",\n",
    "    \"Home or Private?\" : \"at_home\",\n",
    "}\n",
    "\n",
    "# this happens for 2016-2017.xlsx, 2020-2021.xlsx, 2021-2022.xlsx, 2022-2023.xlsx, 2023-2024.xlsx\n",
    "# if dfs has columns that are not in the mapping, we drop them\n",
    "\n",
    "dfs['2016-2017.xlsx'] = dfs['2016-2017.xlsx'].drop(columns=[c for c in dfs['2016-2017.xlsx'].columns if c not in mapping])\n",
    "dfs['2020-2021.xlsx'] = dfs['2020-2021.xlsx'].drop(columns=[c for c in dfs['2020-2021.xlsx'].columns if c not in mapping])\n",
    "dfs['2021-2022.xlsx'] = dfs['2021-2022.xlsx'].drop(columns=[c for c in dfs['2021-2022.xlsx'].columns if c not in mapping])\n",
    "dfs['2022-2023.xlsx'] = dfs['2022-2023.xlsx'].drop(columns=[c for c in dfs['2022-2023.xlsx'].columns if c not in mapping])\n",
    "dfs['2023-2024.xlsx'] = dfs['2023-2024.xlsx'].drop(columns=[c for c in dfs['2023-2024.xlsx'].columns if c not in mapping])\n",
    "\n",
    "\n",
    "dfs['2016-2017.xlsx'] = dfs['2016-2017.xlsx'].rename(columns=mapping)\n",
    "dfs['2020-2021.xlsx'] = dfs['2020-2021.xlsx'].rename(columns=mapping)\n",
    "dfs['2021-2022.xlsx'] = dfs['2021-2022.xlsx'].rename(columns=mapping)\n",
    "dfs['2022-2023.xlsx'] = dfs['2022-2023.xlsx'].rename(columns=mapping)\n",
    "dfs['2023-2024.xlsx'] = dfs['2023-2024.xlsx'].rename(columns=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to fix the rest of the dataframes, the order looks fine, but let's change the names, ( we are not using the above standard because we do not have the at_home column, yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now map the rest to this columns variable\n",
    "columns = ['street_number','street_name','street_suffix','unit_number','zip_code','level_of_study','full_time','extra_large_unit']\n",
    "# rename 2017-2018.xlsx, 2018-2019.xlsx, 2019-2020.xlsx\n",
    "dfs['2017-2018.xlsx'].columns = columns\n",
    "dfs['2018-2019.xlsx'].columns = columns\n",
    "dfs['2019-2020.xlsx'].columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the missing columns to the first group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fix the missing from the 2016-2017.xlsx, 2020-2021.xlsx, 2021-2022.xlsx, 2022-2023.xlsx, 2023-2024.xlsx\n",
    "def fix_columns(df, columns):\n",
    "    for c in columns:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "dfs['2016-2017.xlsx'] = fix_columns(dfs['2016-2017.xlsx'], columns)\n",
    "dfs['2020-2021.xlsx'] = fix_columns(dfs['2020-2021.xlsx'], columns)\n",
    "dfs['2021-2022.xlsx'] = fix_columns(dfs['2021-2022.xlsx'], columns)\n",
    "dfs['2022-2023.xlsx'] = fix_columns(dfs['2022-2023.xlsx'], columns)\n",
    "dfs['2023-2024.xlsx'] = fix_columns(dfs['2023-2024.xlsx'], columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reordering everything to make sure everything is in the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df,columns):\n",
    "    return df[columns]\n",
    "\n",
    "dfs['2016-2017.xlsx'] = reorder(dfs['2016-2017.xlsx'], columns)\n",
    "dfs['2017-2018.xlsx'] = reorder(dfs['2017-2018.xlsx'], columns)\n",
    "dfs['2018-2019.xlsx'] = reorder(dfs['2018-2019.xlsx'], columns)\n",
    "dfs['2019-2020.xlsx'] = reorder(dfs['2019-2020.xlsx'], columns)\n",
    "dfs['2020-2021.xlsx'] = reorder(dfs['2020-2021.xlsx'], columns)\n",
    "dfs['2021-2022.xlsx'] = reorder(dfs['2021-2022.xlsx'], columns)\n",
    "dfs['2022-2023.xlsx'] = reorder(dfs['2022-2023.xlsx'], columns)\n",
    "dfs['2023-2024.xlsx'] = reorder(dfs['2023-2024.xlsx'], columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the at_home column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add at_home to the rest of the dataframes\n",
    "dfs['2016-2017.xlsx']['at_home'] = np.nan\n",
    "dfs['2017-2018.xlsx']['at_home'] = np.nan\n",
    "dfs['2018-2019.xlsx']['at_home'] = np.nan\n",
    "dfs['2019-2020.xlsx']['at_home'] = np.nan\n",
    "dfs['2020-2021.xlsx']['at_home'] = np.nan\n",
    "dfs['2021-2022.xlsx']['at_home'] = np.nan\n",
    "dfs['2022-2023.xlsx']['at_home'] = np.nan\n",
    "dfs['2023-2024.xlsx']['at_home'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do what we did to every other dataset, add university and year range so we know exactly where the data came from when workin with the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add year_range\n",
    "for df in dfs:\n",
    "    dfs[df]['year_range'] = df.split('.')[0]\n",
    "\n",
    "# add university\n",
    "for df in dfs:\n",
    "    dfs[df]['university'] = 'Northeastern University'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dataframes\n",
    "df = pd.concat([dfs['2016-2017.xlsx'], dfs['2017-2018.xlsx'], dfs['2018-2019.xlsx'], dfs['2019-2020.xlsx'], dfs['2020-2021.xlsx'], dfs['2021-2022.xlsx'], dfs['2022-2023.xlsx'], dfs['2023-2024.xlsx']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "df.to_csv('./data/clean/NortheasternUniversity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
